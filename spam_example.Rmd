---
title: "spam_example"
author: "Harrison Li"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(earth)
library(tidyverse)
library(splines)
```

```{r}
DIR <- "/Users/harrisonli/Documents/iCloud_Documents/Stanford/Combining_RCT_and_observational_data/"
X_NAMES <- paste("V", 1:22, sep="")
```

# Helper functions

```{r}
# Returns a list of K indices dividing indices 1:n at random into
# K folds as equally sized as possible
get_fold_inds <- function(n, K, seed=NULL) {
  if (K == 1) {
    inds <- list()
    inds[[1]] <- 1:n
    return(inds)
  }
  set.seed(seed)
  perm <- sample(n)
  cut_ind <- cut(1:n, breaks=K, labels=FALSE)
  return(lapply(1:K, function(k) perm[which(cut_ind==k)]))
}
```

```{r}
# Return indices of outcomes in y that are kept according to the following rule:
# - Independently keep each zero outcome in y with probability p0 
# - Independently keep each one outcome with probability p1
filter_outcomes <- function(y, p0, p1) {
  n <- length(y)
  f0 <- rbinom(n=n, size=1, prob=p0)
  f1 <- rbinom(n=n, size=1, prob=p1)
  return(which((y==0 & f0) | (y==1 & f1)))
}
```

```{r}
# Fits nuisance functions using GLM's
# msz_hat estimates msz(x) = E(Y | X=x,S=s,Z=z) for s, z in {0, 1}
# p_hat estimates p(x) = Pr(S=1 | X=x) = E(S | X=x)
# r_hat estimates r(x) = Pr(Z=1 | X=x,S=0) = E(Z | X=x,S=0)
fit_nuisance_functions <- function(df) {
  start <- Sys.time()
  df_xy <- df[,colnames(df) %in% c("y", X_NAMES)]
  y_form <- formula(paste("y ~", paste(X_NAMES, collapse="+")))
  z_form <- formula(paste("z ~", paste(X_NAMES, collapse="+")))
  s_form <- formula(paste("s ~", paste(X_NAMES, collapse="+")))
  
  mean_model_11 <- suppressWarnings(glm(y_form, family=binomial(link="logit"),
                                        data=df, subset=(df$s==1 & df$z==1)))
  mean_model_10 <- suppressWarnings(glm(y_form, family=binomial(link="logit"),
                                        data=df, subset=(df$s==1 & df$z==0)))
  mean_model_01 <- suppressWarnings(glm(y_form, family=binomial(link="logit"),
                                        data=df, subset=(df$s==0 & df$z==1)))
  mean_model_00 <- suppressWarnings(glm(y_form, family=binomial(link="logit"),
                                        data=df, subset=(df$s==0 & df$z==0)))
  r_model <- suppressWarnings(glm(z_form, family=binomial(link="logit"),
                                        data=df, subset=(df$s==0)))
  p_model <- suppressWarnings(glm(s_form, family=binomial(link="logit"), 
                                  data=df))
  return(list(m11=mean_model_11, m10=mean_model_10, m01=mean_model_01,
              m00=mean_model_00, r=r_model, p=p_model))
}
```


```{r}
# Adds nuisance function predictions to df. 
# model_list is a list of nuisance models returned from 
# get_nuisance_estimates() 
# Estimates of [0, 1] valued functions truncated to [1/sqrt(n), 1-1/sqrt(n)]
# for n the number of observations used for fitting
add_nuisance_predictions <- function(df, model_list) {
  df$m11_hat <- pmax(1/sqrt(length(model_list[["m11"]]$y)),
                    pmin(1-1/sqrt(length(model_list[["m11"]]$y)),
                          predict(model_list$m11, newdata=df, type="response")))
  df$m10_hat <- pmax(1/sqrt(length(model_list[["m10"]]$y)),
                    pmin(1-1/sqrt(length(model_list[["m10"]]$y)),
                          predict(model_list$m10, newdata=df, type="response")))
  df$m01_hat <- pmax(1/sqrt(length(model_list[["m01"]]$y)),
                    pmin(1-1/sqrt(length(model_list[["m01"]]$y)),
                          predict(model_list$m01, newdata=df, type="response")))
  df$m00_hat <- pmax(1/sqrt(length(model_list[["m00"]]$y)),
                    pmin(1-1/sqrt(length(model_list[["m00"]]$y)),
                        predict(model_list$m00, newdata=df, type="response")))
  df$r_hat <- pmax(1/sqrt(length(model_list[["r"]]$y)),
                    pmin(1-1/sqrt(length(model_list[["r"]]$y)),
                         predict(model_list$r, newdata=df, type="response")))
  df$p_hat <- pmax(1/sqrt(length(model_list[["p"]]$y)),
                    pmin(1-1/sqrt(length(model_list[["p"]]$y)),
                        predict(model_list$p, newdata=df, type="response")))
  df$v11_hat <- df$m11_hat * (1-df$m11_hat)
  df$v10_hat <- df$m10_hat * (1-df$m10_hat)
  df$v01_hat <- df$m01_hat * (1-df$m01_hat)
  df$v00_hat <- df$m00_hat * (1-df$m00_hat)
  return(df)
}
```

```{r}
## Function to fit and add nuisance estimates to df
## Nuisance estimates use K-fold cross-fitting 
add_nuisance_estimates <- function(df, K, seed=NULL) {
  
  ## Split df into folds
  N <- nrow(df)
  if (K > 1) {
    fold_inds <- get_fold_inds(N, K, seed=seed)
    df_split <- lapply(fold_inds, function(inds) df[inds,])
    out_of_fold_dfs <- lapply(1:K, function(k) df[do.call("c", fold_inds[-k]),])
  } else {
    fold_inds <- list(1:N)
    df_split <- list(df)
    out_of_fold_dfs <- list(df)
  }
  
  ## Learn out-of-fold nuisance estimates
  nuisance_estimates <- lapply(out_of_fold_dfs, fit_nuisance_functions)
  
  ## Apply nuisance estimates to in-fold data, and combine into single df
  df_aug <- do.call("rbind",
                    lapply(1:K, function(k) {
                             add_nuisance_predictions(df=df_split[[k]],
                              model_list=nuisance_estimates[[k]])
                     }))
  return(df_aug)
}
```

```{r}
# Computes baseline estimator for tau_rct
# Baseline estimator is efficient in the absence of structural assumptions
compute_baseline_estimator <- function(df) {
  
  ## If nuisance estimates not provided, estimate them
  if (!all(c("m11_hat", "m10_hat", "m01_hat", "m00_hat", "p_hat", "r_hat")
    %in% names(df))) {
    stop("df does not have necessary columns containing nuisance estimates")
  }
  rho_hat <- mean(df$s)
  
  ## Compute estimator
  rho_hat <- mean(df$s)
  reg <- with(df, mean(s*(m11_hat-m10_hat))) / rho_hat
  adj <- with(df, mean(s*(z*(y-m11_hat)/e - (1-z)*(y-m10_hat)/(1-e)))) / rho_hat
  return(reg+adj)
}
```

```{r}
# Estimates control variates
# Adapted from https://github.com/serenalwang/multisource-causal-public/blob/
#   main/data_sampler.py
get_CV_estimate <- function(df, x_in, seed=NULL){
  model_list <- fit_nuisance_functions(df)
  rct_trunc <- abs(min(qlogis(1/sqrt(length(model_list[["m11"]]$y))), 
                       qlogis(1/sqrt(length(model_list[["m10"]]$y)))))
  log_OR_rct_pred <- predict(model_list$m11, newdata=x_in, type="link") - 
                       predict(model_list$m10, newdata=x_in, type="link")
  log_OR_rct <- pmin(rct_trunc, pmax(log_OR_rct_pred, -rct_trunc))
  
  obs_trunc <- abs(min(qlogis(1/sqrt(length(model_list[["m01"]]$y))), 
                       qlogis(1/sqrt(length(model_list[["m00"]]$y)))))
  log_OR_obs_pred <- predict(model_list$m01, newdata=x_in, type="link") - 
    predict(model_list$m00, newdata=x_in, type="link")
  log_OR_obs <- pmin(obs_trunc, pmax(log_OR_obs_pred, -obs_trunc))
  return(mean(log_OR_rct-log_OR_obs))
}
```

```{r}
# Computes CV adjustment by bootstrapping df n_replicates times 
get_CV_adj_boot <- function(df, n_replicates, K, x_in, seed=NULL) {

  ## Estimate variance components of control variates via bootstrap
  n <- nrow(df)
  boot_estimates <- matrix(NA, nrow=n_replicates, ncol=2)
  for (r in 1:n_replicates) {
    if (!is.null(seed)) {
      set.seed(seed+r)
    }
    
    ## Bootstrap rct_data and obs_data
    boot_ind <- sample(x=n, size=n, replace=TRUE)
    df_boot <- df[boot_ind,]
    
    ## Estimate tau
    df_boot_aug <- add_nuisance_estimates(df=df_boot, K=K, seed=seed)
    baseline_boot <- compute_baseline_estimator(df=df_boot_aug)
    
    ## Estimate CV's
    CV_estimates_boot <- get_CV_estimate(df=df_boot_aug, x_in=x_in, seed=seed)
    boot_estimates[r,] <- c(baseline_boot, CV_estimates_boot)
  }
  Sigma <- cov(boot_estimates)
  opt_adj <- Sigma[1,2] / Sigma[2, 2]
  return(opt_adj)
}
```

```{r}
# Compute efficient estimators
compute_eff_estimator <- function(df) {
  
  ## Baseline estimator
  tau_hat <- compute_baseline_estimator(df)
  rho_hat <- mean(df$s)
  
  # Enforce odds ratio transportability in estimates
  df$m11_hat <- with(df, plogis(qlogis(m10_hat) + qlogis(m01_hat) -
                                  qlogis(m00_hat)))
  df$v11_hat <- df$m11_hat * (1-df$m11_hat)

  Sig <- as.vector(with(df, 1/v11_hat+e/(v10_hat*(1-e))+
                          p_hat*e/(v01_hat*(1-p_hat)*r_hat)+
                          p_hat*e/(v00_hat*(1-p_hat)*(1-r_hat))))
  gepsf1 <- as.vector(with(df, (p_hat>0)*(1/e+1/(1-e))) / rho_hat)

  ## Learn out-of-fold best influence function estimates via regression
  df$h_hat <- gepsf1 / Sig
  
  return(tau_hat - mean(with(df,
                   as.vector(s*z*(y-m11_hat)/v11_hat-
                             s*(1-z)*e/(1-e)*(y-m10_hat)/v10_hat-
                             (1-s)*z*(y-m01_hat)*p_hat*e/((1-p_hat)*r_hat*v01_hat) +
                             (1-s)*(1-z)*(y-m00_hat)*p_hat*e/((1-p_hat)*(1-r_hat)*v00_hat))*h_hat)))
}
```

```{r}
# Runs bootstrap sims
run_bootstrap_sims <- function(n_sims, df, K, x_in, CV_adj, h_adj=NULL, seed=NULL) {
  init_seed <- seed
  if (!all(c("y", "s", "z", "e") %in% colnames(df))) {
    stop("df needs columns 'y', 's', 'z', and 'e'")
  }
  
  ## Preallocate space for estimators
  tau_hat_baseline <- rep(NA, n_sims)
  tau_hat_cv <- rep(NA, n_sims)
  tau_hat_eff <- rep(NA, n_sims)
  
  for (sim in 1:n_sims) {
    if (sim %% 10 == 0) {
      print(paste("Running bootstrap simulation", sim, "of", n_sims))
    }
    set.seed(seed)
    
    ## Get bootstrapped data
    N <- nrow(df)
    df_boot <- df[sample(x=N, size=N, replace=TRUE),]
    
    ## Add nuisance estimates
    df_boot_aug <- add_nuisance_estimates(df=df_boot, K=K, seed=seed)
    
    ## Nonparametric baseline
    tau_hat_baseline[sim] <- compute_baseline_estimator(df_boot_aug)
    
    ## Control variates estimator
    cv_estimate <- get_CV_estimate(df=df_boot, x_in=x_in, seed=seed)
    tau_hat_cv[sim] <- tau_hat_baseline[sim] - CV_adj * cv_estimate
    
    ## Efficient estimator
    tau_hat_eff[sim] <- compute_eff_estimator(df_boot_aug)
    
    ## Set new seed
    if (!is.null(seed)) {
      seed <- seed + sim
    }
  }
  return(list(estimators=cbind(baseline=tau_hat_baseline, cv=tau_hat_cv, 
                               eff=tau_hat_eff),
              K=K, x_in=x_in, CV_adj=CV_adj, n_rct=sum(df$s),
              init_seed=init_seed))   
}
```

# Read in and process data

```{r}
# Raw experimental datasets
rct_df_mod1 <- read_csv(paste(DIR, "spam_binMod11.csv", sep="")) %>%
  rename(y=Y, z=A) 
rct_df_mod2 <- read_csv(paste(DIR, "spam_binMod21.csv", sep="")) %>%
  rename(y=Y, z=A)

# Raw observational datasets
obs_df_mod1 <- read_csv(paste(DIR, "spam_binMod1_large1.csv", sep=""))  %>%
  rename(y=Y, z=A)
obs_df_mod2 <- read_csv(paste(DIR, "spam_binMod2_large1.csv", sep=""))  %>%
  rename(y=Y, z=A)
```
```{r}
# Random sample of 50 X's from experimental data frame at which to compute CV's
set.seed(2024)
x_in_mod1 <- rct_df_mod1[sample(1:nrow(rct_df_mod1), size=50), X_NAMES]
x_in_mod2 <- rct_df_mod2[sample(1:nrow(rct_df_mod2), size=50), X_NAMES]
```


```{r}
# Takes raw experimental and observational data frames and process them
process_data <- function(rct_df_raw, obs_df_raw, seed) {
  set.seed(seed)
  
  ## Subject observational data to selection
  select_inds <- sample(filter_outcomes(obs_df_mod1$y, p0=0.1, p1=0.9),
                        size=30000, replace=FALSE)
  obs_df <- obs_df_raw[select_inds,]
  
  ## Combine experimental and observational data into single data frame
  df <- rbind(rct_df_raw, obs_df)
  df$s <- c(rep(1, nrow(rct_df_raw)), rep(0, nrow(obs_df)))
  return(df)
}
```

```{r}
# Final data frames for analysis
df_mod1 <- process_data(rct_df_raw=rct_df_mod1, obs_df_raw=obs_df_mod1, seed=1)
df_mod2 <- process_data(rct_df_raw=rct_df_mod2, obs_df_raw=obs_df_mod2, seed=1)
```

# Run simulations

```{r}
run_sims <- function(df, n_rct_list, n_sims, K, x_in, CV_seed, seed) {
  if (max(n_rct_list) > sum(df$s)) {
    stop(paste("No elements of n_rct_list can be larger than ", sum(df$s),
               ", the number of experimental observations"))
  }
  rct_ind <- which(df$s==1)
  obs_ind <- which(df$s==0)
  sim_out_rct_list <- vector("list", length(n_rct_list))
  for (i in 1:length(n_rct_list)) {
    n_rct <- n_rct_list[i]
    print(paste("n_rct =", n_rct))
    set.seed(n_rct)
    rct_sub_ind <- sample(rct_ind, size=n_rct, replace=FALSE)
    curr_df <- df[c(rct_sub_ind, obs_ind),]
    CV_adj <- get_CV_adj_boot(df=curr_df, n_replicates=n_sims, K=K, x_in=x_in, 
                              seed=CV_seed)
    
    ## Compute all estimators
    sim_out_rct_list[[i]] <- run_bootstrap_sims(n_sims=n_sims, df=curr_df, K=K, 
                                                x_in=x_in, CV_adj=CV_adj, 
                                                h_adj=h_adj, seed=seed)
  }
  return(sim_out_rct_list)
}
```

```{r}
n_rct_list <- c(3000, 10000)
```

```{r}
mod1_out <- run_sims(df=df_mod1, n_rct_list=n_rct_list, n_sims=1000,
                     K=5, x_in=x_in_mod1, CV_seed=1, seed=2)
```
```{r}
## Save simulations
# saveRDS(object=mod1_out, file=paste(DIR, "spam_out_mod1", sep=""))
```

```{r}
mod2_out <- run_sims(df=df_mod2, n_rct_list=n_rct_list, n_sims=1000,
                          K=5, x_in=x_in_mod2, CV_seed=1, seed=2)
```

```{r}
# saveRDS(object=mod2_out, file=paste(DIR, "spam_out_mod2", sep=""))
```

# Plot results of sims

```{r}
mod1_out <- readRDS(paste(DIR, "spam_out_mod1", sep=""))
mod2_out <- readRDS(paste(DIR, "spam_out_mod2", sep=""))
```

```{r}
## Get true value of estimand
get_estimand <- function(mod) {
  if (mod == 1) {
    return(0.1062868)
  } else if (mod == 2) {
    return(0.1852917)
  } else {
    stop("mod must be 1 or 2")
  }
}
```

```{r}
# Generate confidence interval for percent differences
# Assumes first column of estimators contains the baseline
pct_diff_boot <- function(estimators, tau, boot_seed, alpha=0.05, B=10000) {
  set.seed(boot_seed)
  n <- nrow(estimators)
  bias_sq_raw <- (colMeans(estimators) - tau)^2
  var_raw <- apply(estimators, MARGIN=2, var)
  mse_raw <- bias_sq_raw + var_raw
  bias_sq_star <- 100 * (bias_sq_raw[-1] - bias_sq_raw[1]) / bias_sq_raw[1]
  var_star <- 100 * (var_raw[-1] - var_raw[1]) / var_raw[1]
  mse_star <- 100 * (mse_raw[-1] - mse_raw[1]) / mse_raw[1]
  bias_sq_boot <- matrix(NA, B, ncol=ncol(estimators)-1)
  var_boot <- matrix(NA, B, ncol=ncol(estimators)-1)
  mse_boot <- matrix(NA, B, ncol=ncol(estimators)-1)
  for (b in 1:B) {
    boot_est <- estimators[sample(n, n, replace=TRUE),]
    bias_sq_list <- (colMeans(boot_est) - tau)^2
    var_list <- apply(boot_est, MARGIN=2, var)
    mse_list <- bias_sq_list + var_list
    bias_sq_boot[b,] <- 100 * (bias_sq_list[-1] - bias_sq_list[1]) / bias_sq_list[1]
    var_boot[b,] <- 100 * (var_list[-1] - var_list[1]) / var_list[1]
    mse_boot[b,] <- 100 * (mse_list[-1] - mse_list[1]) / mse_list[1]
  }
  return(list(bias_sq=rbind(2*bias_sq_star - apply(bias_sq_boot, 2, quantile, 1-alpha/2),
                            2*bias_sq_star - apply(bias_sq_boot, 2, quantile, alpha/2)),
              var=rbind(2*var_star - apply(var_boot, 2, quantile, 1-alpha/2),
                        2*var_star - apply(var_boot, 2, quantile, alpha/2)),
              mse=rbind(2*mse_star - apply(mse_boot, 2, quantile, 1-alpha/2),
                        2*mse_star - apply(mse_boot, 2, quantile, alpha/2))))
}
```

```{r}
# Bootstrap CI's of relative efficiencies
# Assumes first column of estimators is the baseline
rel_eff_boot <- function(estimators, tau, boot_seed, alpha=0.05, B=10000) {
  set.seed(boot_seed)
  n <- nrow(estimators)
  bias_sq_raw <- (colMeans(estimators) - tau)^2
  var_raw <- apply(estimators, MARGIN=2, var)
  mse_raw <- bias_sq_raw + var_raw
  bias_sq_star <- bias_sq_raw[1] / bias_sq_raw[-1]
  var_star <- var_raw[1] / var_raw[-1]
  mse_star <- mse_raw[1] / mse_raw[-1]
  bias_sq_boot <- matrix(NA, B, ncol=ncol(estimators)-1)
  var_boot <- matrix(NA, B, ncol=ncol(estimators)-1)
  mse_boot <- matrix(NA, B, ncol=ncol(estimators)-1)
  for (b in 1:B) {
    boot_est <- estimators[sample(n, n, replace=TRUE),]
    bias_sq_list <- (colMeans(boot_est) - tau)^2
    var_list <- apply(boot_est, MARGIN=2, var)
    mse_list <- bias_sq_list + var_list
    bias_sq_boot[b,] <- bias_sq_list[1] / bias_sq_list[-1]
    var_boot[b,] <- var_list[1] / var_list[-1]
    mse_boot[b,] <- mse_list[1] / mse_list[-1]
  }
  return(list(bias_sq=rbind(bias_sq_star,
                            2*bias_sq_star - apply(bias_sq_boot, 2, quantile, 1-alpha/2),
                            2*bias_sq_star - apply(bias_sq_boot, 2, quantile, alpha/2)),
              var=rbind(var_star,
                        2*var_star - apply(var_boot, 2, quantile, 1-alpha/2),
                        2*var_star - apply(var_boot, 2, quantile, alpha/2)),
              mse=rbind(mse_star,
                        2*mse_star - apply(mse_boot, 2, quantile, 1-alpha/2),
                        2*mse_star - apply(mse_boot, 2, quantile, alpha/2))))
}
```

```{r}
## Plots MSE, squared bias, and variance 
plot_sims <- function(sim_out_list, mod, titles=TRUE, xaxl=TRUE) {
  all_names <- c("baseline", "cv", "eff")
  plot_names <- c("ba", "cv", "eff")
  
  n_sims <- length(sim_out_list)
  param_list <- vector("list", length=n_sims)
  estimand_list <- vector("list", length=n_sims)
  bias_sq_est <- vector("list", length=n_sims)
  var_est <- vector("list", length=n_sims)
  mse_est <- vector("list", length=n_sims)
  boot_out <- vector("list", length=n_sims)
  n_rct_list <- rep(NA, n_sims)
  tau <- get_estimand(mod=mod)
  for (sim in 1:n_sims) {
    sim_out <- sim_out_list[[sim]]
    N <- sim_out$n_rct + 30000
    rho <- sim_out$n_rct / N
    n_rct_list[sim] <- sim_out$n_rct
    estimators <- sim_out$estimators[,all_names]
    boot_out[[sim]] <- rel_eff_boot(estimators=estimators, tau=tau, 
                                    boot_seed=2024)
    bias_sq_est[[sim]] <- (colMeans(estimators) - tau)^2
    var_est[[sim]] <- apply(estimators, MARGIN=2, var)
    mse_est[[sim]] <- bias_sq_est[[sim]] + var_est[[sim]]
  }
  
  ## Compute MSE, squared bias, and variance
  bias_sq_df <- as.data.frame(do.call("rbind", bias_sq_est), n_rct=n_rct_list)
  var_df <- as.data.frame(do.call("rbind", var_est))
  mse_df <- as.data.frame(do.call("rbind", mse_est))
  colnames(bias_sq_df) <- plot_names
  colnames(var_df) <- plot_names
  colnames(mse_df) <- plot_names
  
  ## Plot MSE, squared bias, and variance
  par(mfrow=c(1,3))
  colors <- c("black", "red", "forestgreen")
  max_y <- 1.1 * max(mse_df)
  plot(n_rct_list, mse_df[,1], xlab=ifelse(xaxl, "n_rct", ""), ylab="", type="b", 
       main=ifelse(titles, "MSE", ""),
       col="black", lty="solid", lwd=2, ylim=c(0, max_y))
  for (i in 2:length(plot_names)) {
    lines(n_rct_list, mse_df[,i], col=colors[i], type="b", lwd=2,
          lty="solid")
  }
  plot(n_rct_list, var_df[,1], xlab=ifelse(xaxl, "n_rct", ""), ylab="", type="b", 
       main=ifelse(titles, "Variance", ""),
       col="black", lty="solid", lwd=2, ylim=c(0, max_y))
  for (i in 2:length(plot_names)) {
    lines(n_rct_list, var_df[,i], col=colors[i], type="b", lwd=2,
          lty="solid")
  }
  plot(n_rct_list, bias_sq_df[,1], xlab=ifelse(xaxl, "n_rct", ""), ylab="", type="b", 
       main=ifelse(titles, "Squared bias", ""),
       col="black", lty="solid", lwd=2, ylim=c(0, max_y))
  for (i in 2:length(plot_names)) {
    lines(n_rct_list, bias_sq_df[,i], col=colors[i], type="b", lwd=2,
          lty="solid")
  }
  legend(x="topright", legend=plot_names, col=colors, lty="solid")
  
  ## Relative efficiencies
  point_ests <- t(sapply(boot_out, function(x) x$mse[1,]))
  lowers <- t(sapply(boot_out, function(x) x$mse[2,]))
  uppers <- t(sapply(boot_out, function(x) x$mse[3,]))
  
  print("Relative efficiencies [95% CI]:")
  print(round(point_ests, 2))
  print(round(lowers, 2))
  print(round(uppers, 2))
}
```

```{r}
png(paste(DIR, "spambase_mod1.png", sep=""), width=6, height=3, units="in", res=300)
plot_sims(sim_out_list=mod1_out, mod=1)
```

```{r}
png(paste(DIR, "spambase_mod2.png", sep=""), width=6, height=3, units="in", res=300)
plot_sims(sim_out_list=mod2_out, mod=2)
```


